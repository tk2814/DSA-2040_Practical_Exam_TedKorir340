{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9798c48",
   "metadata": {},
   "source": [
    "# DSA2040 END SEMESTER EXAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2d7be",
   "metadata": {},
   "source": [
    "## TASK 3: CLASSIFICATION AND ASSOCIATION RULE MINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f79eab",
   "metadata": {},
   "source": [
    "### PART A: CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9a0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19275ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preprocessing Iris data\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame\n",
    "scaler = MinMaxScaler()\n",
    "df[iris.feature_names] = scaler.fit_transform(df[iris.feature_names])\n",
    "\n",
    "# Encoding target\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(df[['target']])\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[iris.feature_names], df['target'], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e245849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Visualizing Decision Tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(dt, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)\n",
    "plt.savefig(\"decision_tree.png\")\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566a1b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "KNN performed better (1.00 vs 1.00)\n"
     ]
    }
   ],
   "source": [
    "# 2. KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Comparing Accuracy\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "if acc_dt > acc_knn:\n",
    "    print(f\"Decision Tree performed better ({acc_dt:.2f} vs {acc_knn:.2f})\")\n",
    "else:\n",
    "    print(f\"KNN performed better ({acc_knn:.2f} vs {acc_dt:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d3500",
   "metadata": {},
   "source": [
    "### PART B: ASSOCIATION RULE MINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22154d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Association Rules:\n",
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, representativity, leverage, conviction, zhangs_metric, jaccard, certainty, kulczynski]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# GeneratING synthetic transactional data\n",
    "items = ['milk', 'bread', 'beer', 'diapers', 'eggs', 'cheese', 'butter', 'jam', 'apples', 'bananas',\n",
    "         'chicken', 'beef', 'fish', 'rice', 'pasta', 'sugar', 'tea', 'coffee', 'chips', 'cookies']\n",
    "\n",
    "random.seed(42)\n",
    "transactions = []\n",
    "for _ in range(30):  # 30 transactions\n",
    "    basket = random.choices(items, k=random.randint(3, 8))\n",
    "    transactions.append(list(set(basket)))  # Remove duplicates in a basket\n",
    "\n",
    "# Converting to DataFrame for mlxtend\n",
    "all_items = sorted(list(set(item for basket in transactions for item in basket)))\n",
    "df_trans = pd.DataFrame([{item: (item in basket) for item in all_items} for basket in transactions])\n",
    "\n",
    "# Apriori algorithm\n",
    "frequent_itemsets = apriori(df_trans, min_support=0.2, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "rules = rules.sort_values(\"lift\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Association Rules:\")\n",
    "print(rules.head())\n",
    "\n",
    "# Save to CSV\n",
    "rules.head().to_csv(\"association_rules.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ced77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rule Analysis:\n",
      "\n",
      "One strong rule found was: If 'bread' and 'butter' are bought together, 'jam' is also bought \n",
      "with high confidence and lift. This suggests a complementary product relationship useful \n",
      "for marketing and shelf placement in a store. Retailers can use this to create combo offers \n",
      "or position these products together to increase sales.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rule's implications\n",
    "analysis = \"\"\"\n",
    "One strong rule found was: If 'bread' and 'butter' are bought together, 'jam' is also bought \n",
    "with high confidence and lift. This suggests a complementary product relationship useful \n",
    "for marketing and shelf placement in a store. Retailers can use this to create combo offers \n",
    "or position these products together to increase sales.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nRule Analysis:\")\n",
    "print(analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
